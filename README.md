# Dockerization of a Python ETL Pipelines;
## World Countries ETL Pipelines

**Note:** This is the docker **ETL** *assignment* submitted for Core Data Engineer Boot camp

### Description:
This project builds a complete ETL (Extract, Transform, Load) pipeline using Python and PostgreSQL to ingest structured data from the [REST Countries API](https://restcountries.com/). The pipeline parses, transforms, and stores each countryâ€™s metadata thereby enabling meaningful analysis using custom SQL queries. Below is the ETL architecture workflow:

# ETL Architecture Workflow;
+----------------------+       +-----------------------+       +------------------------+
|   REST Countries API |  -->  | Python ETL Script     |  -->  | PostgreSQL (pgAdmin)   |
|   (JSON Responses)   |       | (Requests + psycopg2) |       |   Table: countries     |
+----------------------+       +-----------------------+       +------------------------+

    Extraction (E)                Transformation (T)                  Loading (L)    
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ REST Countries API            â€¢ Merge chunked responses     â€¢ Connect using psycopg2 
â€¢ Two-part data requests        â€¢ Extract nested fields       â€¢ Create table with UNIQUE
â€¢ JSON responses retrieved      â€¢ Format values (strings)     â€¢ Insert with conflict check
                                â€¢ Structure into row tuples;

## ðŸ§ª Setup and running of pipeline Instructions

1. **To start the services:**
    ```bash
    ./run_docker.sh

2. **To run the pipeline**
    ```bash
        docker run -d my_etl_project


